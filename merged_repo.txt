#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
pack_repo_to_text.py
Pakuje wskazane repo/katalog do .tar.gz, liczy SHA-256, koduje Base64
i dzieli na porcje tekstowe PART_XXXX.txt do wklejenia w czacie.

Użycie:
  python pack_repo_to_text.py --repo C:\sciezka\do\repo --out out_text --chunk-kb 200
(albo na Linux/macOS)
  python3 pack_repo_to_text.py --repo ./repo --out ./out_text --chunk-kb 200
"""

import os, sys, tarfile, base64, hashlib, argparse, json, textwrap
from pathlib import Path
from datetime import datetime, timezone
import io

EXCLUDE_DIRS = {'.git', '.hg', '.svn', '__pycache__', '.venv', 'venv', 'env', 'node_modules', 'logs'}
EXCLUDE_FILES = {'.DS_Store', 'Thumbs.db'}

def sha256_bytes(data: bytes) -> str:
    h = hashlib.sha256(); h.update(data); return h.hexdigest()

def iter_files(root: Path):
    for p in root.rglob('*'):
        if p.is_dir():
            rel = p.relative_to(root)
            if any(part in EXCLUDE_DIRS for part in rel.parts):
                continue
            continue
        rel = p.relative_to(root)
        if any(part in EXCLUDE_DIRS for part in rel.parts):
            continue
        if p.name in EXCLUDE_FILES:
            continue
        yield p

def make_tar_gz_bytes(repo_root: Path) -> bytes:
    buf = io.BytesIO()
    with tarfile.open(fileobj=buf, mode='w:gz') as tar:
        for f in iter_files(repo_root):
            arcname = str(f.relative_to(repo_root)).replace('\\','/')
            tar.add(f, arcname=arcname, recursive=False)
    return buf.getvalue()

def split_b64_to_parts(b64_str: str, chunk_kb: int):
    chunk = chunk_kb * 1024
    for i in range(0, len(b64_str), chunk):
        yield b64_str[i:i+chunk]

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument('--repo', required=True, help='Katalog repo do spakowania')
    ap.add_argument('--out', required=True, help='Folder na pliki tekstowe')
    ap.add_argument('--chunk-kb', type=int, default=200, help='Rozmiar porcji w KB (domyślnie 200)')
    args = ap.parse_args()

    repo_root = Path(args.repo).resolve()
    out_dir = Path(args.out).resolve(); out_dir.mkdir(parents=True, exist_ok=True)

    print(f"[INFO] Repo: {repo_root}")
    print(f"[INFO] Out : {out_dir}")

    tgz = make_tar_gz_bytes(repo_root)
    tgz_sha = sha256_bytes(tgz)
    tgz_size = len(tgz)
    print(f"[OK] Tar.gz bytes: {tgz_size} B, sha256={tgz_sha}")

    b64 = base64.b64encode(tgz).decode('ascii')
    parts = list(split_b64_to_parts(b64, args.chunk_kb))
    total_parts = len(parts)
    print(f"[OK] Base64 parts: {total_parts} x ~{args.chunk_kb} KB")

    # manifest .json
    manifest = {
        "generated_at_utc": datetime.now(timezone.utc).isoformat(),
        "repo_root": str(repo_root),
        "tar_gz_sha256": tgz_sha,
        "tar_gz_size_bytes": tgz_size,
        "parts": []
    }

    for idx, chunk in enumerate(parts, start=1):
        fname = out_dir / f"PART_{idx:04d}.txt"
        header = {
            "format": "REPO-TGZ-B64-PART",
            "index": idx,
            "total": total_parts,
            "tar_gz_sha256": tgz_sha,
            "chunk_len": len(chunk)
        }
        # zapis w czytelnym formacie: nagłówek JSON + pusta linia + base64
        content = json.dumps(header, ensure_ascii=False) + "\n\n" + chunk + "\n"
        fname.write_text(content, encoding='utf-8')
        manifest["parts"].append({"file": fname.name, "index": idx, "chunk_len": len(chunk)})

    (out_dir / "MANIFEST.json").write_text(json.dumps(manifest, indent=2, ensure_ascii=False), encoding='utf-8')
    print(f"[DONE] Zapisano {total_parts} plików PART_XXXX.txt + MANIFEST.json do: {out_dir}")

if __name__ == '__main__':
    main()
