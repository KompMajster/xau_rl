# -*- coding: utf-8 -*-
"""
ops/mini_update_ppo.py  – bezpieczny mini-update PPO na świeżych danych.
Użycie:
  python ops/mini_update_ppo.py --timesteps 300000 --train_days 120 --val_days 30 --seed 42
Loguje sporo informacji, żeby w PowerShell zobaczyć pełny stack trace.
"""
import argparse, json, sys, traceback
from pathlib import Path
import pandas as pd, yaml
from gymnasium.wrappers import TimeLimit
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize, VecMonitor, sync_envs_normalization
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.utils import set_random_seed

# ---- CLI
ap = argparse.ArgumentParser()
ap.add_argument("--timesteps", type=int, default=300000)
ap.add_argument("--train_days", type=int, default=120)
ap.add_argument("--val_days", type=int, default=30)
ap.add_argument("--seed", type=int, default=42)
args = ap.parse_args()

def main():
    cfg = yaml.safe_load(open("config.yaml","r",encoding="utf-8"))
    FEAT = cfg["files"]["features_csv"]
    MODEL_PATH = Path(cfg["files"]["model_path"])
    VECNORM_PATH = Path(cfg.get("files",{}).get("vecnorm_path","models/vecnorm_xauusd_m5.pkl"))
    WINDOW = int(cfg.get("window",128))
    COSTS = cfg["costs"]
    ENV_CFG = cfg.get("env",{}) or {}
    REWARD_MODE = ENV_CFG.get("reward_mode", cfg.get("reward_mode","pct"))
    FLIP_PENALTY = float(ENV_CFG.get("flip_penalty", cfg.get("flip_penalty",0.0)))
    TRADE_HOURS = ENV_CFG.get("trade_hours_utc", cfg.get("trade_hours_utc", None))
    MIN_EQ = float(ENV_CFG.get("min_equity", 0.8))

    # Dane
    df = pd.read_csv(FEAT, parse_dates=["time"]).sort_values("time").reset_index(drop=True)
    val_end = df["time"].max()
    val_start = val_end - pd.Timedelta(days=args.val_days)
    train_start = val_start - pd.Timedelta(days=args.train_days)

    train_df = df[(df["time"]>=train_start) & (df["time"]<val_start)].copy()
    val_df   = df[(df["time"]>=val_start)  & (df["time"]<=val_end)].copy()

    print(f"[mini_update] Training on {len(train_df)} rows (~{args.train_days}d), timesteps={args.timesteps}", flush=True)
    if len(train_df) <= WINDOW or len(val_df) <= WINDOW:
        raise RuntimeError(f"Too few rows for window={WINDOW}: train={len(train_df)}, val={len(val_df)}")

    # features_spec (jeśli istnieje)
    features_spec = None
    fspec = Path("models/features_spec.json")
    if fspec.exists():
        features_spec = json.loads(fspec.read_text(encoding="utf-8")).get("feature_columns", None)

    # Środowisko
    from env_xau import XauTradingEnv
    def make_train():
        env = XauTradingEnv(train_df, window=WINDOW,
            spread_abs=COSTS["spread_abs"], commission_rate=COSTS["commission_rate"], slippage_k=COSTS["slippage_k"],
            reward_mode=REWARD_MODE, use_close_norm=True, flip_penalty=FLIP_PENALTY, trade_hours_utc=TRADE_HOURS,
            enforce_flat_outside_hours=True, features_spec=features_spec, min_equity=MIN_EQ)
        return TimeLimit(env, max_episode_steps=6000)

    def make_eval():
        env = XauTradingEnv(val_df, window=WINDOW,
            spread_abs=COSTS["spread_abs"], commission_rate=COSTS["commission_rate"], slippage_k=COSTS["slippage_k"],
            reward_mode=REWARD_MODE, use_close_norm=True, flip_penalty=0.0, trade_hours_utc=TRADE_HOURS,
            enforce_flat_outside_hours=True, features_spec=features_spec, min_equity=MIN_EQ)
        return TimeLimit(env, max_episode_steps=3000)

    set_random_seed(args.seed)
    vtrain = DummyVecEnv([make_train]); vtrain = VecMonitor(vtrain); vtrain = VecNormalize(vtrain, norm_obs=True, norm_reward=True, clip_obs=10.0, clip_reward=10.0)
    veval  = DummyVecEnv([make_eval]);  veval  = VecMonitor(veval);  veval  = VecNormalize(veval, training=False, norm_obs=True, norm_reward=False)
    sync_envs_normalization(veval, vtrain)

    policy_kwargs = dict(net_arch=dict(pi=[128,128], vf=[128,128]))
    tb_log_dir = "logs/ppo_gold_m5"
    model = PPO("MlpPolicy", vtrain, n_steps=4096, batch_size=256, learning_rate=3e-4, ent_coef=0.02,
                policy_kwargs=policy_kwargs, seed=args.seed, verbose=1, tensorboard_log=tb_log_dir)

    eval_cb = EvalCallback(veval, best_model_save_path=str(MODEL_PATH.parent), log_path="logs/eval",
                           eval_freq=max(args.timesteps//4, 10000), n_eval_episodes=1,
                           deterministic=True, render=False)
    model.learn(total_timesteps=args.timesteps, callback=eval_cb)

    MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)
    model.save(str(MODEL_PATH))
    vtrain.save(str(VECNORM_PATH))
    print(f"[mini_update] Saved model -> {MODEL_PATH}")
    print(f"[mini_update] Saved VecNormalize -> {VECNORM_PATH}")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print("\n[mini_update][FATAL] Uncaught exception:\n", file=sys.stderr, flush=True)
        traceback.print_exc()
        sys.exit(1)




$ErrorActionPreference = "Stop"
$REPO = "C:\xau_rl"
$PY   = "$REPO\.venv\Scripts\python.exe"
$LOG  = "$REPO\logs\services\mini_update_ppo.log"
$LOCK = "$REPO\logs\services\mini_update_ppo.lock"

New-Item -ItemType Directory -Force -Path (Split-Path $LOG) | Out-Null
Set-Location $REPO

function Acquire-Lock { if (Test-Path $LOCK) { $false } else { New-Item -ItemType File -Path $LOCK -Force | Out-Null; $true } }
function Release-Lock { if (Test-Path $LOCK) { Remove-Item $LOCK -Force } }

function Run-Once {
    "`n[$(Get-Date -Format o)] [mini_update] start" | Out-File -FilePath $LOG -Append -Encoding utf8
    & $PY -u "ops\mini_update_ppo.py" "--timesteps" "300000" 1>> $LOG 2>> $LOG
    $code = $LASTEXITCODE
    "[$(Get-Date -Format o)] [mini_update] exit_code=$code" | Out-File -FilePath $LOG -Append -Encoding utf8
    if ($code -ne 0) { throw "mini_update failed with exit_code=$code (see log)" }
    "[$(Get-Date -Format o)] [mini_update] done" | Out-File -FilePath $LOG -Append -Encoding utf8
}

while ($true) {
  try {
    if (Acquire-Lock) {
      Run-Once
      Release-Lock
    } else {
      "`n[$(Get-Date -Format o)] [mini_update] skipped (locked)" | Out-File -FilePath $LOG -Append -Encoding utf8
    }
  } catch {
    "[ERROR] $($_ | Out-String)" | Out-File -FilePath $LOG -Append -Encoding utf8
    Release-Lock
  }
  Start-Sleep -Seconds (6*3600)  # co 6h
}
